\chapter{Results}

In this chapter speed measurements of our application will be presented as well as a few pictures of the results.
Because we have not accelerated the computation over traditional processors a discussion of the reasons will follow.
We will mention possible changes in design to speed up the execution.
Then some consideration how shall the algorithm that is well suited for the \mbox{Cell/B.E.} look like.
Chapter will be finished with comparison of complexity of programming for the \mbox{Cell/B.E.} and conventional processors.

\section{Speed measurements}

\par
Actual speed measurement is performed within \mbox{\emph{GenerateData}} method of the \mbox{\emph{FiniteDifferenceFilter}}.
Counter is started right after initialization phase i.e. before main algorithm loop and stopped right after the loop.
The program memory usage was tuned to use only really necessary amount of memory within the measured interval.
Valgrind's massive tool was used for the memory usage tuning.
This was necessary because of the PS3 limited memory, see paragraph \ref{ps3MemoryUsage}

\par
Beside the server memory usage tuning other changes was made also within the client part.
There has been a special filter developed.
The filter shrinks a data set to a given size and cast its voxels to float.
The shrinking is performed by a linear interpolator.
The purpose of the float casting is avoidance of allocation of additional memory on the server side that would be necessary for float data set.

\par
It is strange that the command \emph{top} shows far bigger memory usage than the Valgrind's massif.
We have not cared much about it but the idea is that the \emph{top} shows all memory requested from the system while the massif shows exact memory used by the process.

\par
Results of the speed measurement is summarized in the table \ref{tab:runresults}.
Every measurement was run with the same curvature and speed-scaling factors.
But with different initial distance, maximum iterations and seed parameters.
These parameters were set according to data set size.

\par
Three different data sets were measured.
All of them was CT images of a skull that were scanned for anthropological purposes.
Measurement of some volumetric parameters of such images is a valuable source of data for the anthropologist.
Method implemented in our application could be used in the praxis for such purposes if the application is quick enough.
Therefore speed-up of the current methods is necessary.

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{7}{|c|}{Measurement results}\\
\hline
data set		&size		&seed		&init.		&max. 		&arch.		&time\\
			&		&		&dist-		&itera-		&		&spend\\
			&		&		&ance		&tions		&		&(sec)\\
\hline
\hline
3slices 		&512x512x3	&[256,256,1]	&40		&800		&\mbox{Cell/B.E.}	&16.48\\
(skull 1)		&		&		&		&		&i686	.	&1.89\\
\hline
\hline
skull 1			&256x256x80	&[128,110,20]	&20		&500		&\mbox{Cell/B.E.}	&471.89\\
			&		&		&		&		&i686		&95.23\\
\hline
\hline
skull 1			&256x256x80	&[128,110,20]	&4		&500		&\mbox{Cell/B.E.}	&325.93\\
			&		&		&		&		&i686		&61.74\\
\hline
\hline
skull 2			&256x256x80	&[128,110,20]	&4		&500		&\mbox{Cell/B.E.}	&319.47\\
			&		&		&		&		&i686		&55.88\\
\hline
\hline
skull 2			&256x256x80	&[128,128,40]	&4		&500		&\mbox{Cell/B.E.}	&366.63\\
			&		&		&		&		&i686		&76.9\\
\hline
\end{tabular}
\par
\caption[Measurement results]
{
Results of speed measurement.
The first difference is a bit big probably because of the small data set and insufficient time to take advantage of parallelism of six SPE.
The second measurement shows that the PC implementation is about five times faster.
The rest of measurements, performed on different data set and parameter configurations prove the coefficient five.
}
\label{tab:runresults}
\end{table}

\section{Reasons of slowdown and possible improvements}

\par
Porting the code to run on SPEs and distribution of the calculations among the available SPEs is not sufficient to get more speed from the \mbox{Cell/B.E.} over traditional processors.
The optional speed-up porting phases are necessary to be performed.
But our program has another speed pitfalls.

\par
The biggest problem is the \mbox{CellNeighbourhood} that represent a small part of an image (the $3^3$ voxel matrix).
It is transferred for every layer item.
In some parts the both output and status image neighbourhoods are transferred.
We wanted to perform the transfer in scatter-gather manner through DMA lists but we have faced some problems.
The DMA transfers and specially using DMA lists are designed for big amount of aligned data.
When they are used for small amounts (smaller than 16bytes per list item) performance goes down because of unaligned data transfer.
When smaller than 16 bytes (quad-word) data are being transferred every single item is automatically aligned to quad-word address within the local store buffer (see figure \ref{fg:automaticAlignOfSmallData}).

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{data/automaticAlignOfSmallData}
    \caption[Automatic align of small data]
{
  Illustration of transfer of data that are smaller than quad-word.
  Hardware automatically increases address within the local store buffer in such way that every transferred item is quad-word aligned.
}
    \label{fg:automaticAlignOfSmallData}
\end{figure}

This increase required size of a buffer that is needed for the transfer.
This can be partially solved by usage of multiple DMA lists (one for each quadword align).
This is illustrated in the figure \ref{fg:multipleDMAList}.
For details see \cite{DMAListIssues}.

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{data/multipleDMAList}
    \caption[Multiple DMA list workaround]
{
  Workaround for transfer for smaller than quad-word chunks.
  It uses more than one DMA list.
  One per quad-word align e.g. for chars 16 DMA lists are needed.
}
    \label{fg:multipleDMAList}
\end{figure}

We have adopted this workaround and used it within the neighbourhood transfer.
Because of the automatic local store quadword address aligning we had to use a translation table.
This table maps position of actual neighbourhood members into position within the local store buffer.
This is working solution but overhead is incredible and thus the solution is useless (see cellNeigbourhood.tcc for details).

\par
\label{neighbourhoodDependecy}
Another problem is order of layer nodes resp. neighbourhoods processing.
When there are two nodes within one layer that are next to each other processed subsequently changes made to the first processed neighbourhood would not appear to already preloaded next one.
Therefore another merging was necessary to be performed.
This coerced another changes to neighbourhood transfer and made the actual transfer unbearably expensive operation.

\par
\label{workDependecy}
Another pitfall is the situation when sibling nodes are processed by two different SPEs.
Adding nodes to layers is based on information from neighbours of the currently processed node.
So it is possible that two different SPE inserts the same nodes subsequently into one layer because they process sibling nodes i.e. overlapping neighbourhoods.
This makes no changes to output but means additional overhead due to processing multiplied nodes.
Solution to this problem would require synchronization among the SPEs.

\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{data/png/pcSlice}
    \includegraphics[width=0.45\textwidth]{data/png/cellSlice}
    \caption[Comparison of one slice segmented on different architectures]{Comparison of one slice segmentation on different architectures.
The left was computed on PC (i686), the right on \mbox{Cell/B.E.}
Although the segmentation was run with the same parameters there is small difference between those two images.
The \mbox{Cell/B.E.} level set has not reached as far as the PC one.
It is because of duplicate nodes within layers.
}
    \label{fg:sliceComparison}
\end{figure}

\par
Additional improvements of neighbourhood transfers should be done to speed up the execution.
This corresponds to data transfer optimization step of porting process (see paragraph \ref{fg:appPorting}).
In our case this would mean radical simplification of neighbourhood transfer.
This transfer should take only a few instructions to be effective.
In the SDK examples transfers are performed by simple macros which is probably the most effective way.
In our case simplification if the neighbourhood transfer would mean utilization of bigger image part transport within a single DMA transfer to avoid automatic local store alignment.
This would mean a bigger local store array to store the image part.
But processing of nodes that are associated with the part would be somehow gathered and thus the count of transfers would be lower.
Processing of nodes should take into account their spatial information when inserted into a layer and thus to gather the node processing on the bigger neighbourhood.
But such computation scheme would coerce complete redesign of the application and begining from scratch.

\section{Code and design complexity}

\par
The \mbox{Cell/B.E.} programming means mainly programming for the SPEs because of their performance and count.
Because of indirect memory access and need of usage of some multi-buffering memory transfer scheme the design is quite more complex over common processor.
With another limitation which is the local store size is design of a \mbox{Cell/B.E.} application a challenge.

\par
The \mbox{Cell/B.E.} is designed for intensive computation applications.
For a programmer this means utilization of all SPEs and all their features at the maximum level.
It is only possible for certain class of algorithms.
Let's call them streaming parallel algorithm.
But what is it? What is the definition?
Work on our application has showed us what the streaming parallel algorithm is not.
Therefore by negation of the features that slow down our program we could get a definition of the streaming parallel algorithm.
It would look like the following:

\begin{enumerate}

\item{Streaming nature}
\par
Data of that program are uniform and can be processed in a small pieces (chunks) which are mutually independent and which can fit in the local store memory.
This means that for a chunk processing only this chunk is necessary and not any part of the other chunks.
When this chunk is once processed it is stored and is never retrieved for processing again.

\par
For our application this is not true.
At least not for all the input data.
Processing of a sparse field layer meets the streaming nature.
But processing of parts of underlying images (neighbourhoods) associated with these nodes does not.
The neighbourhoods are mutually dependent see \ref{neighbourhoodDependecy}.

\item{Paralel nature}
\par
Input data can be divided into parts which are again mutually independent and which can be sent to particular cores for processing.
This avoids any mutual synchronizations among the SPEs.

\par
For our application is again not true.
Work that is divided among the cores is not independent because of dependency of particular neighbourhoods.
See \ref{workDependecy} what causes problems.

\end{enumerate}

\par
When algorithm does not meet the streaming parallel definition then it should not be implemented or it must be changed.
This means e.g. to use different data structures or to change the way the current data structures are used.
In our case, change of the data structure to somehow gather node processing to specific image part would mean change of the algorithm we implemented.
But then it would not be the original algorithm any more.

\par
In contrast there are algorithms that fits the streaming parallel algorithm definition.
The examples in the SDK that meet the definition.
Except them e.g. thresholding meets the definition as well.
It operates on an image that has uniform data - pixels.
It apply simple condition on each pixel which result depends only on the processed pixel.
Processing can be divided into chunks.
These three features meets the streaming condition.
Moreover the data can be divided into independent sets that can be processed by multiple cores (the parallel nature).
Implementation of this algorithm can therefore result huge performance gain on the \mbox{Cell/B.E.} than conventional processors.

\par
Our work has showed importance of the initial consideration and the design phase.
When there are more algorithms that are solving a desirable problem programmer should think carefully which one will be the best for porting to the \mbox{Cell/B.E.}
First stage of the initial consideration should be a model of the application implementing chosen algorithm.
Consideration what kind of data are processed.
If they are uniform.
If they are divisible into chunks.
If the computing can be divided into independent parts i.e. what entity defines amount of work to be done.
These are questions that lead to answer if the chosen algorithm is or is not the streaming parallel.
If the answer is no, implementation of that algorithm is rather worthless and will result such a suboptimal program as the ours.

\par
Another thing is the code complexity.
Performing the optimisation porting cycle steps utilise all the \mbox{Cell/B.E.} features and thus leads to gain more performance.
Usage of language intrinsics, different kind of special instruction of macros for variety of purposes, multi-buffering, etc. increases actual code complexity whereas decreases code readability.
It is also time consuming and hard to perform.

\par
There is still another question to be answered.
Is the porting of an algorithm worth at all?
Since only some special machines are equipped with the \mbox{Cell/B.E.} actual data have to be sent to the machine for computing and results have to be sent back.
Therefore only complex algorithms where performance gain would be bigger than the time spent in transfer of actual data set are worth to port.
The algorithm we have tried to implement is complex enough to be offloaded to compute on remote machine while the mentioned thresholding would not.
As soon as common machines such as notebooks, desktops are equipped with the \mbox{Cell/B.E.} processor even a class of such simple image processing algorithms that is implemented in everyday-use software such as the thresholding or variety of masking or edge detections is worth to port.

\chapter{Conclusion}

\par
At the beginning we studied available literature to find out what is actually the \mbox{Cell/B.E.} and what benefits it brings.
What special features it has and what they are good for.
Then we have been trying to install SDK to start actual development process.
During this phase we faced some obstacles such as bugs, incompatibilities among tools, the libraries that the tools use and even the operating system vs. SDK incompatibilities.
Therefore we had to go through variety of forums and other sources to find the solutions.
As a side effect we improved our Linux knowledge.
Eventually we managed to install SDK and was able to start developing.
Then we have been testing variety libraries, tools and examples to get familiar with the \mbox{Cell/B.E.} development.

\par
We have chosen sparse field algorithm implementing level set based segmentation to port to \mbox{Cell/B.E.} platform.
This is quite complex algorithm to test the platform's potential.
We adopted ITK implementation of that algorithm.
Therefore we had to study ITK tool kit and its internals.
We have also incorporated the whole program into MedV4D framework.
That means we have implemented new modules that allow using ITK and can offload some part of processing to remote machine.

\par
Actual porting process started with cleenup the ITK code.
Then profiling of existing application took place finding out hot spots of the code which can be in turn offloaded to SPE to take advantage of \mbox{Cell/B.E.}.
But profiling results was quite unexpected so another redesign of application followed.
In this new design almost whole original ITK code was offloaded to the SPE.
A big code restructuring was necessary to allow us to perform actual computations on the SPE.
We have repeatedly debugged same kind of errors due to corruptions of stack memory caused by DMA transfers.
This has proved importance of usage memory checking tools.
Finally we have been able to run the whole algorithm on SPE and to measure time need for computations.

\par
The result of measurement showed that simple move the computation to the SPEs is not sufficient because it does not utilize all the \mbox{Cell/B.E.} features.
We have identified some bottlenecks of the application and discussed possible solutions.
Implementation of these solutions would require whole application redesign using another data structure.
These changes would actually mean change of the used algorithm.

\par
Because of complexity of the chosen algorithm and the base implementation we spent so much time with uninterresting work and in many cases we have done the porting process in wrong way.
This lead to silly mistakes and another time wastings in debugging bugs.
But on the other hand the improvization was the reason of appearing of interresting ideas like the PC as the \mbox{Cell/B.E.} simulator.

\par
Our work has proven that taking an implementaion of an algorithm and gradually change it to let it run on the SPE is not a good way of proting process.
Instead it is necessary to think if the algorithm is well suited for porting.
And if it is then implement it from scratch considering all the \mbox{Cell/B.E.} features utilization already from beginning.
The gradually changing the original implementation with the idea of utilisation all the \mbox{Cell/B.E.} features as soon as it is able to run at least on the SPE is wrong.
Then it could meand the whole application redesign like in our case.

\par
We have also discussed differences between the programming for conventional processors and \mbox{Cell/B.E.}
As well as question of actual algorithm complexity and worthiness of porting them to \mbox{Cell/B.E.}

\par
The \mbox{Cell/B.E.} platform is very interesting for its variations of use scenarios and ability of program tuning and customization.
We think the pallet of tools and features of the \mbox{Cell/B.E.} can make it interesting alternative to conventional processors whose lifetime is getting shorter due to limitations in manufacturing process.
The \mbox{Cell/B.E.}'s great potential has already been proven but it is still waiting for wider spectrum of programmers.

\par
If the process of the \mbox{Cell/B.E.} development starting became simpler we believe much more new programmers would start using and programming it.
Nowadays there are plenty of information about the \mbox{Cell/B.E.} but they are somehow unsorted or out of date.
The best information source are documents shipped along with the SDK.
But they are targeted to contain all the information regardless the level of experience of the reader.
That means when a programmer wants to start developing applications on the \mbox{Cell/B.E.} he/she would go trough a plenty of that information before he/she can start actual work.
It is a pity there is total lack of information for PS3 users within SDK documentation.
This is quite problem when a major part of beginners has a PS3 available.
There is simply lack of some 'cookbook for beginners' with practical information and some howtos.
We believe this work could be such a cookbook with such practical information that potentially may help to some other programmers who would like to start developing for the \mbox{Cell/B.E.}
